
# ğŸ§  Meeting Summarizer

## ğŸ“– Introduction
Meeting Summarizer is a full-stack web application that automatically transcribes and summarizes meeting audio using AI and NLP models. It streamlines the process of capturing, transcribing, and summarizing meetings, making it easy to extract key insights and share them with your team.

---

## âœ¨ Features
- ğŸ¤ Audio Upload & Real-time Transcription (Whisper ASR)
- ğŸ“ Automatic Summarization (LLM)
- ğŸ“„ Downloadable transcripts and summaries
- âš¡ Simple, responsive UI (React)
- ğŸ”— RESTful API integration (Flask)
- ğŸ›¡ï¸ Secure storage of meeting data

---

## ğŸ—ï¸ Architecture

```
User â”€â”€â–¶ Frontend (React) â”€â”€â–¶ Backend (Flask) â”€â”€â–¶ ASR & LLM Models
  â–²             â”‚                â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      SQLite DB & File Storage
```

- **Frontend:** Handles file upload, displays transcript and summary, interacts with backend APIs.
- **Backend:** Receives audio, runs ASR (speech-to-text), sends transcript to LLM for summarization, stores results.
- **Database:** SQLite for storing transcripts and summaries.

---

## ğŸ“‚ Project Structure
```
Meeting-Summarizer-Project/
â”‚
â”œâ”€â”€ backend/                  # ğŸ Flask backend
â”‚   â”œâ”€â”€ app.py                # Main Flask application
â”‚   â”œâ”€â”€ asr_client.py         # Handles ASR (speech-to-text)
â”‚   â”œâ”€â”€ llm_client.py         # Handles LLM summarization
â”‚   â”œâ”€â”€ models.py             # Database models
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â”œâ”€â”€ db.sqlite3            # SQLite database (default)
â”‚   â”œâ”€â”€ .env                  # Environment variables
â”‚   â”œâ”€â”€ instance/
â”‚   â”‚   â””â”€â”€ db.sqlite3        # SQLite database (alternate location)
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ uploads/          # Uploaded audio files
â”‚   â””â”€â”€ __pycache__/          # Python cache files
â”‚
â”œâ”€â”€ frontend/                 # âš›ï¸ React frontend
â”‚   â”œâ”€â”€ package.json          # NPM dependencies and scripts
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html        # Main HTML file
â”‚   â”‚   â””â”€â”€ robots.txt        # Robots exclusion file
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js            # Main React app
â”‚   â”‚   â”œâ”€â”€ App.test.js       # App tests
â”‚   â”‚   â”œâ”€â”€ index.js          # Entry point
â”‚   â”‚   â”œâ”€â”€ index.css         # Global styles
â”‚   â”‚   â”œâ”€â”€ reportWebVitals.js# Web vitals reporting
â”‚   â”‚   â”œâ”€â”€ setupTests.js     # Test setup
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioUpload.js        # Audio upload component
â”‚   â”‚   â”‚   â”œâ”€â”€ SummaryDisplay.js     # Summary display component
â”‚   â”‚   â”‚   â””â”€â”€ TranscriptDisplay.js  # Transcript display component
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â”œâ”€â”€ App.css               # App styles
â”‚   â”‚       â”œâ”€â”€ AudioUpload.css       # Audio upload styles
â”‚   â”‚       â”œâ”€â”€ SummaryDisplay.css    # Summary display styles
â”‚   â”‚       â””â”€â”€ TranscriptDisplay.css # Transcript display styles
â”‚
â””â”€â”€ README.md                # Project documentation
```

---

## âš¡ Quick Start & Installation

### 1ï¸âƒ£ Clone the repository
```powershell
git clone https://github.com/KotaNagaSeetha/MeetingSummarizer.git
cd MeetingSummarizer
```

### 2ï¸âƒ£ Backend Setup
```powershell
cd backend
python -m venv venv
venv\Scripts\activate  # (Windows)
pip install -r requirements.txt
```

### 3ï¸âƒ£ Frontend Setup
Open a new terminal:
```powershell
cd frontend
npm install
npm start
```

---

## ğŸš€ Usage
1. Start the backend server:
   ```powershell
   python app.py
   ```
2. Start the frontend development server:
   ```powershell
   npm start
   ```
3. Open your browser at [http://localhost:3000](http://localhost:3000)
4. Upload an audio file, view the transcript, and get the summary.

---

## ğŸ› ï¸ Development

### Manual Setup
- Ensure Python 3.8+ and Node.js 16+ are installed.
- Backend dependencies: see `backend/requirements.txt`
- Frontend dependencies: see `frontend/package.json`

### Environment Variables
- Create a `.env` file in `backend/` for API keys and secrets:
  ```env
  GOOGLE_AI_STUDIO_API_KEY=your_google_ai_studio_key
  FLASK_SECRET_KEY=your_secret
  ...
  ```
- To get your Google AI Studio API key, sign up at [Google AI Studio](https://aistudio.google.com/) and generate your API key from your account dashboard.

### API Endpoints (Backend)
- `POST /upload` â€” Upload audio file
- `GET /transcript/<id>` â€” Get transcript
- `GET /summary/<id>` â€” Get summary

## Backend
- **Tech Stack:** Python, Flask
- **Key Files:**
  - `app.py`: Main Flask application
  - `asr_client.py`: Handles ASR (speech-to-text)
  - `llm_client.py`: Handles communication with LLM (summarization)
  - `models.py`: Database models
  - `requirements.txt`: Python dependencies
- **Setup:**
  1. Navigate to `backend/`
  2. Install dependencies:
     ```powershell
     pip install -r requirements.txt
     ```
  3. Set up environment variables in `.env` as needed
  4. Run the server:
     ```powershell
     python app.py
     ```

## Frontend
- **Tech Stack:** React
- **Key Files:**
  - `src/App.js`: Main React app
  - `src/components/AudioUpload.js`: Audio upload component
  - `src/components/TranscriptDisplay.js`: Transcript display
  - `src/components/SummaryDisplay.js`: Summary display
- **Setup:**
  1. Navigate to `frontend/`
  2. Install dependencies:
     ```powershell
     npm install
     ```
  3. Start the development server:
     ```powershell
     npm start
     ```


---

## âš ï¸ Safety & Notes
- Do not share your API keys publicly.
- Uploaded files are stored locally; ensure disk space and privacy.
- For production, use HTTPS and secure your Flask secret key.

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

## ğŸ§  Troubleshooting

If you encounter any issues while running the project, consider the following:

- Ensure both the **frontend** and **backend** servers are running correctly.  
- Verify that your **Gemini API key** is properly set in the `.env` file.  
- Confirm that your **audio file** is valid and within size limits (preferably under 10MB).  
- Check the **browser console** or **backend logs** for any specific error messages.  
- Restart both servers after making configuration changes.

---

## ğŸŒŸ Future Enhancements
- ğŸ”Š Real-time streaming transcription
- ğŸŒ Multi-language support
- ğŸ§¾ Speaker diarization
- â˜ï¸ Cloud integration for storage & retrieval

---

## ğŸ¥ Demo Video

Watch the demo of **MeetingSummarizer** here:  
https://drive.google.com/file/d/12JE8qlKb6d_O2aj-szR964BVZSgMnUFg/view?usp=drive_link

---

## ğŸ™Œ Acknowledgments

Special thanks to **OpenAI Whisper** and **Gemini API** for providing the core AI components that power this project.  
Designed and developed by [KOTA NAGA SEETHA](https://github.com/KotaNagaSeetha).
